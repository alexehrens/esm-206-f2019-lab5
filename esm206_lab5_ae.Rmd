---
title: "ESM 206 Lab 5"
author: "Alex Ehrens"
date: "10/29/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#### Lab 5 objectives

- Learn to parse dates with "lubridate"
- Get counts of observations with count()
- Uncount() rows 
- One and two-sample t-test
- Create a heatmap with geom_tile()

```{r, include = FALSE}
# Read in data and attach packages
library(tidyverse)
library(here)
library(janitor)

lobster_abundance <- read_csv(here::here("data", "lobster_abundance.csv"),
                              na = "-99999") %>% 
  janitor::clean_names()

```

Use tidyr::uncount() function to convert our lobster data from frequency format to case format

```{r}
lobster_tidy <- lobster_abundance %>% 
  tidyr::uncount(lobster_count) # only need to put column name of column to uncount
```

### Exploratory data visualization

We're only going to consider "site" as our variable of interest

```{r}

ggplot(lobster_tidy, aes(x = site, y = size_mm)) +
  geom_jitter(aes(color = site),
              alpha = 0.5,
              width = 0.2)

# Histogram - separate histogram for each site
ggplot(lobster_tidy, aes(x = size_mm)) +
  geom_histogram(aes(fill = site)) +
  facet_wrap(~site, scales = "free") #scales default to be the same for each facet, can adjust with scales = "free" argument

# Use quantile-quantile plot to test for normality
ggplot(lobster_tidy, aes(sample = size_mm)) +
  geom_qq() + #default of geom_qq() is comparison to normal distribution
  facet_wrap(~site) 

```

From histograms and quantile-quantile plots, it looks like these data follow pretty close to normally distributed (because linear alignment with normal distribution in qq plot). 

If sample has 30 or more counts, central limit theorem tells you that means are normally distributed even if data doesn't appear normally distributed so you can still use a T-test or other parametric test.

#### Convert the 'date' column to class "Date"

We'll use the 'lubridate' package to convert to Date format, and then to help us easily parse month & year

```{r}

lobster_date <- lobster_tidy %>% 
  mutate(date_new = lubridate::mdy(date))

```

Now let's parse year and month using lubridate::month() and lubridate::year():

```{r}

lobster_parse_date <- lobster_date %>% 
  mutate(obs_month = lubridate::month(date_new, label = TRUE), #default is to pull out month #, can change to month abbreviation by adding label = TRUE
         obs_year = lubridate::year(date_new)) 

```

Now let's find counts of observed lobsters based on different hierarchical groupings:

First: let's count lobsters by year and month:
```{r}
lobster_ym <- lobster_parse_date %>% 
  dplyr::count(obs_year, obs_month) #only have to list variables by which you want to group counts

lobster_y <- lobster_parse_date %>% 
  dplyr::count(obs_year)

lobster_site <- lobster_parse_date %>% 
  dplyr::count(site)

# having data in tidy format makes it easier to do counts by how we want to group things
```

If we want to create a summary table that contains statistics other than counts by group, it's easier to use group_by() + n() function because count function specifically by to do a group_by() within itself, but not externally.

```{r}
lobster_summary <- lobster_parse_date %>% 
  group_by(site) %>% 
  summarize(
    mean_size = mean(size_mm, na.rm = TRUE),
    sd_size = sd(size_mm, na.rm = TRUE),
    lobster_number = n()) 
# if you want to use multiple statistics by group, use group_by(), summarize(), and n() function
```

using n() requires group_by() and summarize, count() assumes you want to group_by() and summarize() and automatically does it, tally() you need to use group_by() but automatically summarizes

#### Find confidence intervals

Use t.test() function to find confidence intervals (for one sample) and perform t-tests to compare means of two samples (...this will be covered conceptually in lectures week 6)

```{r}
ivee_lobster <- lobster_tidy %>% 
  filter(site == "IVEE") %>% 
  pull(size_mm) # to pull out column from data frame as vector

t.test(ivee_lobster) # can store this as something if you want

# p-value = if null hypothesis is true, probability that random sample from population is exactly than mean 

```

#### Two-sample t-test to compare means

We want to ask: Is there a significant different in lobster lengths at Naples and Mohawk reefs?

We've done our necessary exploratory analyses to determine that a two-sample t-test for means comparison is appropriate.

```{r}

napl_sample <- lobster_tidy %>% 
  filter(site == "NAPL") %>% 
  pull(size_mm)

mohk_sample <- lobster_tidy %>% 
  filter(site == "MOHK") %>% 
  pull(size_mm)

mn_ttest <- t.test(mohk_sample, napl_sample)

mn_ttest


```

There is a significant different in lobster lengths between Naples and Mohawk Reef (t(df) = statistic, p < 0.001, alpha = 0.05).

```{r}

lobster_mn <- lobster_tidy %>% 
  filter(site %in% c("NAPL", "MOHK"))

mn_ttest2 <- t.test(size_mm ~ site, data = lobster_mn) # ~ means "as a function of"

mn_ttest2 # same results as separated vector form

mn_ttest2$p.value
mn_ttest2$statistic

```

There is a sig diff (t(1850.8) = -19.849, p = 2.2e-16). NOT REPRODUCIBLE AT ALL

Here is the p-value: `r mn_ttest2$p.value`

Here is my t-statistic: `r mn_ttest2$statistic`

This is how to reference in-text so variable shows up in Markdown document. Makes sure you don't have to manually copy and paste any values every time code is updated. Happens automatically.

#### Now: a heatmap

```{r}
lobster_ys <- lobster_parse_date %>% 
  count(obs_year, site)

ggplot(data = lobster_ys, aes(x = obs_year, y = site)) +
  geom_tile(aes(fill = n))
```

